{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de Copie de ModOAP_Telechargement_structure_blocs_texte_Gallica.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTQfLyIKMpOn"
      },
      "source": [
        "# ModOAP - Téléchargement des blocs de texte de documents Gallica\n",
        "\n",
        "Ce carnet propose de spécifier l'**identifiant ark** d'un document ou une **liste d'identifiants** dans une colonne d'un fichier excel, pour **télécharger les blocs de texte** dans un fichier structuré au format **json**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPEj_4bOQBwV",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45695b1c-1bc3-4b3f-927d-de94ed71e406"
      },
      "source": [
        " #@markdown ### Préparation et connexion à un compte Google Drive\n",
        "#@markdown Lancer cette cellule, puis cliquer sur le lien généré par Google pour connecter un compte Drive si demandé.\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# chargement d'un google drive\n",
        "if not os.path.exists(\"/content/drive/MyDrive/\") :\n",
        "  drive.mount('/content/drive/')\n",
        "\n",
        "import requests\n",
        "from openpyxl import load_workbook\n",
        "import urllib.request, urllib.error, urllib.parse\n",
        "from urllib.error import HTTPError, URLError\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "try :\n",
        "  import xmltodict\n",
        "except :\n",
        "  !pip -q install xmltodict\n",
        "  import xmltodict\n",
        "import unicodedata\n",
        "import re \n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def remove_accents(s):\n",
        "  # In : chaine avec caractères diachrités\n",
        "  # Out : chaine sans accent\n",
        "  return ''.join((c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn'))\n",
        "\n",
        "def normalisation_titre(titre):\n",
        "  # In : chaine titre\n",
        "  # Out : chaine titre pour nom de fichier\n",
        "  titre = remove_accents(titre)\n",
        "  titre = re.sub('[^a-zA-Z0-9- ]', '', titre)\n",
        "  titre = re.sub('[ ]', '_', titre)\n",
        "  return \"_\".join(titre.split(\"_\")[:6])\n",
        "\n",
        "def get_var_ts(ts) :\n",
        "  # In : text string (mot) (ordered dict key, list ou dict)\n",
        "  # ajoute le contenu du mot au contenu du bloc texte\n",
        "  if isinstance(ts, list) :\n",
        "    for mot in ts :\n",
        "      contenu = mot[\"@CONTENT\"]\n",
        "      text_block_words.append(contenu)\n",
        "  else :\n",
        "    contenu = ts[\"@CONTENT\"]\n",
        "    text_block_words.append(contenu)\n",
        "\n",
        "def get_content(tlentry) :\n",
        "  # In : textline (ordered dict key, list ou dict)\n",
        "  # lance get_var_ts\n",
        "  if isinstance(tlentry, list) :\n",
        "    for tl in tlentry :\n",
        "      get_var_ts(tl[\"String\"])\n",
        "  else : get_var_ts(tlentry[\"String\"])\n",
        "\n",
        "def get_var_tb(tb) :\n",
        "  # In : textblock (ordered dict key, dict)\n",
        "  # récupère la position et l'id du bloc texte\n",
        "  # lance get_var_tb\n",
        "  width = tb[\"@WIDTH\"]\n",
        "  height = tb[\"@HEIGHT\"]\n",
        "  hpos = tb[\"@HPOS\"]\n",
        "  vpos = tb[\"@VPOS\"]\n",
        "  id = tb[\"@ID\"]\n",
        "  get_content(tb[\"TextLine\"])\n",
        "  return width, height, hpos, vpos, id\n",
        "\n",
        "def get_tb(tb_entry) :\n",
        "  # In : textblock (ordered dict key, list ou dict)\n",
        "  # récupère la position et l'id du bloc texte\n",
        "  # lance get_var_tb\n",
        "  if isinstance(tb_entry, list) :\n",
        "    for tb in tb_entry :\n",
        "      width, height, hpos, vpos, id = get_var_tb(tb)\n",
        "  else : \n",
        "    width, height, hpos, vpos, id = get_var_tb(tb_entry)\n",
        "  return width, height, hpos, vpos, id\n",
        "\n",
        "def block_treatment(tb, num_page) :\n",
        "  # In :  textblock (ordered dict key), numéro de page (int)\n",
        "  # lance get_tb\n",
        "  # ajoute la position et le contenu du bloc texte dans un dictionnaire\n",
        "  global text_block_words\n",
        "  text_block_words = []\n",
        "  width, height, hpos, vpos, id = get_tb(tb)\n",
        "  contenu = \" \".join(text_block_words)\n",
        "  position_dic = {\"width\" : width, \"height\" : height, \"hpos\" : hpos, \"vpos\" : vpos}\n",
        "  dico_id = {\"Page_Num\" : num_page, \"Position\" : position_dic, \"Content\" : contenu}\n",
        "  text_blocks[id] = dico_id\n",
        "\n",
        "def infos_doc(ark):\n",
        "  # In :  identifiant ark\n",
        "  # Out : titre, date de publication du document (str)\n",
        "  url_biblio = \"https://gallica.bnf.fr/services/OAIRecord?ark=\"+ark\n",
        "  s = requests.get(url_biblio, stream=True)\n",
        "  bibliodico = xmltodict.parse(s.text)\n",
        "  try :\n",
        "    titre = bibliodico[\"results\"][\"title\"]\n",
        "  except :\n",
        "    titre = \"unknown\"\n",
        "  try :\n",
        "    date_pub = bibliodico[\"results\"][\"date\"][\"#text\"]\n",
        "  except :\n",
        "    date_pub = \"unknown\"\n",
        "  return titre, date_pub\n",
        "\n",
        "\n",
        "def nombre_pages(ark):\n",
        "  # In :  identifiant ark\n",
        "  # Out : nombre de pages (int)\n",
        "  PAGINATION_BASEURL = 'https://gallica.bnf.fr/services/Pagination?ark='\n",
        "  url = \"\".join([PAGINATION_BASEURL, ark])\n",
        "  s = requests.get(url, stream=True)\n",
        "  paginationdic = xmltodict.parse(s.text)\n",
        "  nb_pages = int(paginationdic[\"livre\"][\"structure\"][\"nbVueImages\"])\n",
        "  return nb_pages\n",
        "\n",
        "def ark_processing(ark) :\n",
        "  # In :  identifiant ark\n",
        "  # Out : fichier json contenant : \n",
        "    # titre, date, nombre de pages du document\n",
        "    # id, position, contenu des blocs de textes de chaque page\n",
        "\n",
        "  titre, date_pub = infos_doc(ark)\n",
        "  titre_fichier = normalisation_titre(titre)  \n",
        "  try :\n",
        "    nombre_pagess = nombre_pages(ark)\n",
        "  except :\n",
        "    print(\"Pagination indisponible, document non-téléchargé : \", ark)\n",
        "\n",
        "  print(\"Titre du document : \", titre)\n",
        "  print(\"Dossier de destination : \", destination_dir)\n",
        "  print(\"Téléchargement des blocs de texte :\")\n",
        "\n",
        "  info_doc = {\"Titre\" : titre, \"Publication_Date\" : date_pub, \"Total_Pages\" : nombre_pagess }\n",
        "  global text_blocks \n",
        "  text_blocks = {}\n",
        "\n",
        "  # Pour chaque page du document :\n",
        "  for num_page in tqdm(range(1,nombre_pagess+1)) :\n",
        "  #for num_page in range(1,10) : \n",
        "    #print(\"page \",num_page,\" / \",str(nombre_pagess))\n",
        "    # Transforme le fichier OCR ALTO de la page en un dictionnaire :\n",
        "    alto_url = 'https://gallica.bnf.fr/RequestDigitalElement?O='+ark+'&E=ALTO&Deb='+str(num_page)\n",
        "    s = requests.get(alto_url, stream=True)\n",
        "    altodic = xmltodict.parse(s.text)\n",
        "    # Si un ou plusieurs blocs de texte sont directement présents dans le PrintSpace : \n",
        "    try :\n",
        "      tb_entry = altodic['alto'][\"Layout\"][\"Page\"][\"PrintSpace\"][\"TextBlock\"]\n",
        "      if isinstance(tb_entry, list) :\n",
        "        for tb in tb_entry :\n",
        "          block_treatment(tb, num_page)\n",
        "        \n",
        "      else :\n",
        "        block_treatment(tb_entry, num_page)\n",
        "    except :\n",
        "      pass\n",
        "    # Si un ou plusieurs blocs composés sont présents dans le PrintSpace : \n",
        "    try :\n",
        "      cb_entry = altodic['alto'][\"Layout\"][\"Page\"][\"PrintSpace\"][\"ComposedBlock\"]\n",
        "      if isinstance(cb_entry, list) :\n",
        "        for cb in cb_entry :\n",
        "          tb_entry = cb[\"TextBlock\"]\n",
        "          if isinstance(tb_entry, list) :\n",
        "            for tb in tb_entry :\n",
        "              block_treatment(tb, num_page)\n",
        "          else :\n",
        "            block_treatment(tb_entry, num_page)\n",
        "      else :\n",
        "        tb_entry = cb_entry[\"TextBlock\"]\n",
        "        if isinstance(tb_entry, list) :\n",
        "          for tb in tb_entry :\n",
        "            block_treatment(tb, num_page)\n",
        "        else :\n",
        "          block_treatment(tb_entry, num_page)\n",
        "    except :\n",
        "      pass\n",
        "  # Création du fichier final :\n",
        "  jsondic = {\"Infos_Doc\" : info_doc, \"Text_Blocks\" : text_blocks} \n",
        "  with open(os.path.join(destination_dir,str(date_pub)+\"_\"+titre_fichier+\"_\"+ark+\"_texte_structure.json\"), 'w') as jout :\n",
        "    json.dump(jsondic, jout)\n",
        "  print(\"Le texte du document a été sauvegardé dans le fichier \", os.path.join(destination_dir,str(date_pub)+\"_\"+titre_fichier+\"_\"+ark+\"_texte_structure.json\"))\n",
        "\n",
        "def bnf2gall(arkbnf):\n",
        "  # In :  identifiant ark au format type cb453908509\n",
        "  # Out : identifiant ark au format type bpt6k9799524x (consultable sur Gallica)\n",
        "  url = \"https://catalogue.bnf.fr/ark:/12148/\"+str(arkbnf)\n",
        "  s = requests.get(url, stream=True)\n",
        "  html = BeautifulSoup(s.content) # html5lib\n",
        "  for link in html.findAll('a', {'class': 'exemplaire-action-visualiser'}):\n",
        "    ark = link['href'].split(\"/\")[-1]\n",
        "  return ark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LNNnDqqEA1V",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b399d7d-e831-45b0-cb5f-85393d565df8"
      },
      "source": [
        "#@markdown ### A partir d'un identifiant ARK :\n",
        "#@markdown ---\n",
        "#@markdown Entrer l'identifiant ARK d'un document, puis lancer la cellule.\n",
        "\n",
        "ark = \"btv1b8618381s\" #@param {type:\"string\"}\n",
        "#@markdown Exemple d'identifiant:\n",
        "#@markdown bpt6k9799524x ou cb453908509\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Entrer le chemin du répertoire souhaité, puis lancer la cellule.\n",
        "\n",
        "destination_dir = \"/content/drive/MyDrive/dossier_test\" #@param {type:\"string\"}\n",
        "#@markdown Exemple de chemin:\n",
        "#@markdown /content/drive/My Drive/datasets/\n",
        "\n",
        "#@markdown Possibilité de copier/coller le chemin depuis la fenêtre de gauche : onglet \"Fichiers\" -> clic droit sur un dossier -> \"Copier le chemin\"\n",
        "\n",
        "if ark.startswith(\"cb\") :\n",
        "  ark = bnf2gall(ark)\n",
        "ark_processing(ark)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Titre du document :  Les Minutes de sable : mémorial / Alfred jarry\n",
            "Dossier de destination :  /content/drive/MyDrive/dossier_test\n",
            "Téléchargement des blocs de texte :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 249/249 [01:40<00:00,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le texte du document a été sauvegardé dans le fichier  /content/drive/MyDrive/dossier_test/1894_Les_Minutes_de_sable__memorial_btv1b8618381s_texte_structure.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0BNtzm_mq0m",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcdb4822-8865-4206-d547-7f9afdb3edea"
      },
      "source": [
        "#@markdown ### Ou bien à partir d'un fichier excel :\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown Entrer le chemin vers le fichier (xlsx ou xlsm) et l'indice de la colonne, puis lancer la cellule.\n",
        "chemin_fichier_xls = \"/content/drive/MyDrive/dossier_test/FPLAB_3docs_pour_telechargement_strucure.xlsx\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Exemple de chemin : /content/drive/MyDrive/Document/documents.xlsx\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Entrer l'indice de la colonne contenant les liens ARK :\n",
        "colonne_ark = \"A\" #@param {type:\"string\"}\n",
        "#@markdown Exemple d'indice : A\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Entrer le chemin du répertoire souhaité, puis lancer la cellule.\n",
        "\n",
        "destination_dir = \"/content/drive/MyDrive/dossier_test\" #@param {type:\"string\"}\n",
        "#@markdown Exemple de chemin:\n",
        "#@markdown /content/drive/My Drive/datasets/\n",
        "\n",
        "arks_done = [rk.split(\"_\")[-3] for rk in glob.glob(os.path.join(destination_dir,\"*.json\"))]\n",
        "\n",
        "try :\n",
        "  if not os.path.exists(destination_dir):\n",
        "      os.makedirs(destination_dir)\n",
        "except :\n",
        "  print(\"Le chemin de destination est incorrect\")\n",
        "\n",
        "arks_doc = []\n",
        "\n",
        "# Chargement du fichier xls\n",
        "try :\n",
        "  classeur= load_workbook(chemin_fichier_xls)\n",
        "except :\n",
        "  print(\"Le fichier xls n'a pas été chargé correctement\")\n",
        "\n",
        "for onglet in classeur.sheetnames:\n",
        "  onglet_courant = classeur[onglet]\n",
        "  colonne = onglet_courant[colonne_ark]\n",
        "  for cellule in colonne :\n",
        "    if str(cellule.value).startswith(\"http\") or str(cellule.value).startswith(\"ark\"):\n",
        "      arks_doc.append(str(cellule.value).split(\"/\")[-1].strip())\n",
        "    elif str(cellule.value).startswith(\"cb\") or str(cellule.value).startswith(\"bp\"):\n",
        "      arks_doc.append(str(cellule.value))\n",
        "\n",
        "print(\"{0} liens récupérés dans {1} onglets\".format(len(arks_doc), len(classeur.sheetnames)))\n",
        "\n",
        "arks_doc = set(arks_doc)\n",
        "\n",
        "for ark in arks_doc :\n",
        "  if ark.startswith(\"cb\") :\n",
        "    try :\n",
        "      ark = bnf2gall(ark)\n",
        "    except :\n",
        "      pass\n",
        "  if ark not in arks_done :\n",
        "    try :\n",
        "      ark_processing(ark)\n",
        "    except :\n",
        "      print(\"Le document {} n'a pas été téléchargé\".format(ark))\n",
        "      pass\n",
        "  else : print(\"Le document {} est déjà téléchargé\".format(ark))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 liens récupérés dans 1 onglets\n",
            "Titre du document :  Manuel d'histoire de France : contenant les tableaux d'histoire des mêmes auteurs / par MM. Meissas et Michelot\n",
            "Dossier de destination :  /content/drive/MyDrive/dossier_test\n",
            "Téléchargement des blocs de texte :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 113/168 [00:47<00:23,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le document bpt6k96919287 n'a pas été téléchargé\n",
            "Titre du document :  A. B. C. de l'histoire universelle : contenant les faits caractéristiques et les évènements principaux de chaque siècle depuis la création jusqu'à nos jours, et pouvant servir d'introduction et de récapitulation à l'étude de l'histoire (Nouvelle édition, corrigée et augmentée) / par Édouard W. d'Halluvin,...\n",
            "Dossier de destination :  /content/drive/MyDrive/dossier_test\n",
            "Téléchargement des blocs de texte :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [01:27<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le texte du document a été sauvegardé dans le fichier  /content/drive/MyDrive/dossier_test/1867_A_B_C_de_lhistoire_universelle_bpt6k9690982q_texte_structure.json\n",
            "Titre du document :  Histoire de France à l'usage des écoles primaires : cours élémentaire (5e édition) / par Gustave Hubault\n",
            "Dossier de destination :  /content/drive/MyDrive/dossier_test\n",
            "Téléchargement des blocs de texte :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 116/116 [00:50<00:00,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le texte du document a été sauvegardé dans le fichier  /content/drive/MyDrive/dossier_test/1880_Histoire_de_France_a_lusage_des_bpt6k96911895_texte_structure.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8fgcHmeHaB8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}